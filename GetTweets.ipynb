{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import datetime \n",
    "from twitter_authentication import bearer_token\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('data') == False:\n",
    "    os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('logs') == False:\n",
    "    os.mkdir('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"./logs/std.log\", \n",
    "\t\t\t\t\tformat='%(asctime)s %(message)s', \n",
    "\t\t\t\t\tfilemode='a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"This is just a harmless debug message\") \n",
    "logger.info(\"This is just an information for you\") \n",
    "logger.warning(\"OOPS!!!Its a Warning\") \n",
    "logger.error(\"Have you try to divide a number by zero\") \n",
    "logger.critical(\"The Internet is not working....\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTC Train Set 2017 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_name = \"BTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime(2016,12,31,23,0,0)\n",
    "date_list = []\n",
    "for i in range(0, 3 * 365 * 24 + 1):\n",
    "    date += datetime.timedelta(hours=1)\n",
    "    date_str = date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    date_list.append(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in range(0, len(date_list) - 1):\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    logger.info(\"\") \n",
    "    logger.info(date_list[j])\n",
    "    logger.info(date_list[j+1])\n",
    "\n",
    "    for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                    query = '#btc OR #bitcoin OR #bitcointrading -is:retweet lang:en',\n",
    "                                    user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                    tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                    expansions = 'author_id',\n",
    "                                    start_time = date_list [j],\n",
    "                                    end_time = date_list [j+1],\n",
    "                                    max_results=10,  \n",
    "                                    limit=25):\n",
    "        \n",
    "        time.sleep(1)\n",
    "        tweets_list.append(response)\n",
    "        \n",
    "    \n",
    "    if count % 24 == 0:\n",
    "        \n",
    "        logger.info(\"output to csv\")\n",
    "        \n",
    "        path = './data/'+ asset_name + '__' + date_list[j][0:10] + '.csv'\n",
    "        \n",
    "        result = []\n",
    "        user_dict = {}\n",
    "        \n",
    "        # Loop through each response object\n",
    "        for response in tweets_list:\n",
    "            # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "            for user in response.includes['users']:\n",
    "                user_dict[user.id] = {'username': user.username, \n",
    "                                    'followers': user.public_metrics['followers_count'],\n",
    "                                    'tweets': user.public_metrics['tweet_count'],\n",
    "                                    'description': user.description,\n",
    "                                    'location': user.location\n",
    "                                    }\n",
    "            for tweet in response.data:\n",
    "                # For each tweet, find the author's information\n",
    "                author_info = user_dict[tweet.author_id]\n",
    "                # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "                result.append({'author_id': tweet.author_id, \n",
    "                            'username': author_info['username'],\n",
    "                            'author_followers': author_info['followers'],\n",
    "                            'author_tweets': author_info['tweets'],\n",
    "                            'author_description': author_info['description'],\n",
    "                            'author_location': author_info['location'],\n",
    "                            'text': tweet.text,\n",
    "                            'created_at': tweet.created_at,\n",
    "                            'retweets': tweet.public_metrics['retweet_count'],\n",
    "                            'replies': tweet.public_metrics['reply_count'],\n",
    "                            'likes': tweet.public_metrics['like_count'],\n",
    "                            'quote_count': tweet.public_metrics['quote_count']\n",
    "                            })\n",
    "\n",
    "        # Change this list of dictionaries into a dataframe\n",
    "        df = pd.DataFrame(result)\n",
    "        \n",
    "        df.to_csv(path)\n",
    "        \n",
    "        tweets_list = []\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d100e7957bc88683fb6d449d1832e5831d5f805d77b57e14790aec5169fed04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
